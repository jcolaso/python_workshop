{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing web data:\n",
    "1. Making requests\n",
    "2. Parsing through json data\n",
    "3. Fetching data through html tags using beautiful soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Making requests\n",
    "1. Using requests module\n",
    "\n",
    "There are other libraries that give you the ability to interact with http and make different kind of requests, but in my experience requests() module serves the purpose and is sufficient for majority of the needs. One can also use urllib, urllib2 and urllib3 to do similar tasks as well. If you know how to make web requests in python and don't want to use requests() module, then you can skip this section and continue with xml and html parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the openweather api to demonstrate how http requests are made. Go to <a href='http://openweathermap.org/appid'>this link </a>to create an account and generate an api key. Once you have that you can try to make an api call for the current weather api <a href='http://openweathermap.org/api'>here</a> One api call that can be made is by visiting this url http://api.openweathermap.org/data/2.5/forecast?id=524901&APPID&APPID=your_key you will need to supply your api key for this to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since we've seen how to use the browser to make the api call (it was just a simple url that we were hitting using our browser). Now, let's see how we can do the same task programmatcally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('E:\\Work\\Python\\Python Trainings')\n",
    "f=open('open_weather_api.txt','r')\n",
    "key=f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url='http://api.openweathermap.org/data/2.5/weather?q=London&APPID='\n",
    "url=base_url+key\n",
    "request=requests.get(url.strip())##The raw text file has whitespaces after the key value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out if the request() was successful, one can check the http status codes, A status code of 200, signifies that there is no error. <a href='https://en.wikipedia.org/wiki/List_of_HTTP_status_codes'>Here is a comprehensive list of http error codes and what they mean</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print request.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sometimes the requests() function will not be able to fetch data, this can happen because of the inability of requests() method to mimic the behaviour of a browser, this can be remidied by supplying correct headers. <a href='http://docs.python-requests.org/en/master/user/quickstart/#custom-headers'>See the official docs here to see how supply custom headers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers={'user-agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:51.0) Gecko/20100101 Firefox/51.0'}\n",
    "request=requests.get(url.strip(),headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print request.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can find out the contents of the request by choosing specific request methods. Here is the list of methods:\n",
    "1. <a href='http://docs.python-requests.org/en/master/user/quickstart/#response-content'>Response Content</a>\n",
    "2. <a href='http://docs.python-requests.org/en/master/user/quickstart/#binary-response-content'>Binary Response</a>\n",
    "3. <a href='http://docs.python-requests.org/en/master/user/quickstart/#json-response-content'>JSON Response</a>\n",
    "4. <a href='http://docs.python-requests.org/en/master/user/quickstart/#raw-response-content'> Raw Response</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"coord\":{\"lon\":-0.13,\"lat\":51.51},\"weather\":[{\"id\":310,\"main\":\"Drizzle\",\"description\":\"light intensity drizzle rain\",\"icon\":\"09d\"}],\"base\":\"stations\",\"main\":{\"temp\":287.78,\"pressure\":1010,\"humidity\":87,\"temp_min\":287.15,\"temp_max\":289.15},\"visibility\":10000,\"wind\":{\"speed\":3.6,\"deg\":300},\"clouds\":{\"all\":90},\"dt\":1500875400,\"sys\":{\"type\":1,\"id\":5091,\"message\":0.0047,\"country\":\"GB\",\"sunrise\":1500869588,\"sunset\":1500926402},\"id\":2643743,\"name\":\"London\",\"cod\":200}\n"
     ]
    }
   ],
   "source": [
    "print request.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=request.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'clouds', u'name', u'visibility', u'sys', u'weather', u'coord', u'base', u'dt', u'main', u'id', u'wind', u'cod']\n"
     ]
    }
   ],
   "source": [
    "print data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'pressure': 1010, u'temp_min': 287.15, u'temp_max': 289.15, u'temp': 287.78, u'humidity': 87}\n"
     ]
    }
   ],
   "source": [
    "print data['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Can you extract the country name\n",
    "## Sunset and sunrise time (its been given in unix format)\n",
    "## Use the file Api hands on.docx and answer the questions that follow,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open weather gives you an ability to choose the format of the response you want. By default the response is a json object, though one can get <a href='https://openweathermap.org/current#other'> an xml and an html response as well </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url='http://api.openweathermap.org/data/2.5/weather?q=London&mode=xml&APPID='\n",
    "url=base_url+key\n",
    "request_xml=requests.get(url.strip())##The raw text file has whitespaces after the key value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print request_xml.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(request_xml.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requests module can't handle xml response as there is no method to handle xml data. Eventually every form of response should get converted into a datastructure native to python, when we used the json() method we were able to obtain a dictionary, as you can see there is no method that requests() provides to handle xml data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dir(request_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"xml\" in dir(request_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see that the api exposes an html response as well, but again we don't have a method in the requests class to handle this. Let's use the api to get an html response and then see what response() class's text method returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url='http://api.openweathermap.org/data/2.5/weather?q=London&mode=html&APPID='\n",
    "url=base_url+key\n",
    "request_html=requests.get(url.strip())##The raw text file has whitespaces after the key value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print request_html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(request_html.text)\n",
    "print type(request_html.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('E:\\Work\\Python\\Python Trainings\\Python Advanced\\Code\\Day_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('sample.html','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in request_html.content:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Parsing html using beautifulsoup4\n",
    "We have seen html response earlier from the api call that we had made. One can onbtain the html response if a request is made to a web page. The discussion below focuses on how one can parse an html response obtained via requests module. Again DOM framework will be followed to parse through the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will first look at the basic objects and classes that are provided by bs4.\n",
    "\n",
    "<img src=\"BeautifulSoup.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will read in a file with html markup and then introduce you to bs4 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('E:\\Work\\Python\\Python Trainings\\Python Advanced\\Code\\Day_2')\n",
    "f=open('html.html','r')\n",
    "html=f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##The first thing that one needs to do after acquiring the markup is to convert it into a soup object\n",
    "html_soup=BeautifulSoup(html,'html.parser')\n",
    "print html_soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(html_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look into how following tasks can be done:\n",
    "1. Selecting specific elements (based on html tags)\n",
    "2. Extracting the text from tags\n",
    "3. Traversing the html tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Selecting specific elements\n",
    "head=html_soup.head\n",
    "print type(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Tag Object.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print head.name\n",
    "print head.attr\n",
    "print head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Extracting text from tags\n",
    "print html_soup.head.title\n",
    "print type(html_soup.head.title)\n",
    "print html_soup.head.title.contents\n",
    "print html_soup.head.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Extracting text from tags\n",
    "print html_soup.head.title.string\n",
    "print type(html_soup.head.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Extarcting text from tags\n",
    "print html_soup.head.title.text\n",
    "print type(html_soup.head.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Traversing the html tree\n",
    "# One can go deep into the tree by using appropriate tag methods\n",
    "print html_soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Suppose we want to traverse to the title tag\n",
    "print html_soup.head.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Getting the text\n",
    "print html_soup.head.title.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Suppose we want to traverse to first para in div with class para 1\n",
    "print html_soup.div \n",
    "##only the first occurence of div is returned, while in document there are 3 occurences of div "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print html_soup.div.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## What if we wanted to look at the second para in the tree?\n",
    "print html_soup.div.p.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## What if we wanted to look at the second para in the tree?\n",
    "print html_soup.div.p.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## What if we wanted to look at the second para in the tree?\n",
    "print html_soup.div.p.next_sibling.next_sibling.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## What if we wanted to look at the second para in the tree?\n",
    "print html_soup.div.p.next_sibling.next_sibling.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## What if we wanted to look at the second para in the tree?\n",
    "print html_soup.div.p.next_sibling.next_sibling.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Traversing the html tree\n",
    "# One can go deep into the tree by using appropriate tag methods\n",
    "print html_soup.prettify()\n",
    "#Suppose we wanted to extract the first para in div with class para 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## There are find methods that help us do that\n",
    "print html_soup.find('div',class_='para 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(html_soup.find('div',class_='para 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## There are find methods that help us do that\n",
    "print html_soup.find_all('div',class_='para 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(html_soup.find_all('div',class_='para 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Suppose we wanted to extract all the text within div with class para 1?\n",
    "html_soup.find_all('div',class_='para 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(html_soup.find_all('div',class_='para 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_soup.find_all('div',class_='para 1')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## We can also loop\n",
    "for t in html_soup.find_all('div',class_='para 1'):\n",
    "    print t.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Suppose we wanted only the second paragraph in each div?\n",
    "for t in html_soup.find_all('div',class_='para 1'):\n",
    "    print t.p.next_sibling.next_sibling.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Suppose we wanted only the second paragraph in each div?\n",
    "for t in html_soup.find_all('div',class_='para 1'):\n",
    "    print t.p.next_sibling.next_sibling.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Combining requests + beautifulsoup to extract top 100 favourite movie quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using this http://www.imdb.com/list/ls000029269/ to scrape the quotes and write them out in a text file. A rough sequence of steps would be to:\n",
    "1. Use requests() to get the html markup\n",
    "2. Create a soup object\n",
    "3. Use appropriate Tag methods to grab the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='http://www.imdb.com/list/ls000029269/'\n",
    "imdb_html=requests.get(url)\n",
    "imdb_html=imdb_html.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb_soup=BeautifulSoup(imdb_html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print imdb_soup.prettify()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open('quotes.txt','w')\n",
    "for t in imdb_soup.find_all('div',class_='description'):\n",
    "     f.write(t.text.strip().encode('utf-8')+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in imdb_soup.find_all('div',class_='description'):\n",
    "     print t.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
